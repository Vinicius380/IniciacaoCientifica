{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Saúde SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wever\\AppData\\Local\\Temp\\ipykernel_6272\\3576950970.py:3: DtypeWarning: Columns (12,23,31,33,34,36,37,57,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataSaude = pd.read_csv(r\"C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\part-00000-83dc71c5-fe6e-49f3-9837-6072f3359041.c000.csv\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataSaude = pd.read_csv(r\"C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\part-00000-83dc71c5-fe6e-49f3-9837-6072f3359041.c000.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando por dataNotificacao e sintomas e contando as ocorrências\n",
    "dataSaude['dataNotificacao'] = pd.to_datetime(dataSaude['dataNotificacao'])\n",
    "\n",
    "# Separar os sintomas compostos e expandir para várias linhas\n",
    "dataSaude['sintomas'] = dataSaude['sintomas'].str.split(',')  # Dividir sintomas compostos por vírgula\n",
    "dataSaude = dataSaude.explode('sintomas')  # Expandir para múltiplas linhas por sintoma\n",
    "\n",
    "\n",
    "# Filtrando os sintomas desejados\n",
    "sintomas_desejados = ['Tosse', 'Coriza', 'Dor de Cabeça']\n",
    "df_filtrado = dataSaude[dataSaude['sintomas'].isin(sintomas_desejados)]\n",
    "\n",
    "# Agrupando por dataNotificacao e sintomas e contando as ocorrências\n",
    "df_sintomas = df_filtrado.groupby([df_filtrado['dataNotificacao'].dt.date, 'sintomas']).size().reset_index(name='contagem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wever\\AppData\\Local\\Temp\\ipykernel_6272\\1935208100.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado_municipio['sintomas'] = df_filtrado_municipio['sintomas'].str.split(',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataNotificacao        sintomas  contagem\n",
      "0        2024-11-01          Coriza        83\n",
      "1        2024-11-01   Dor de Cabeça       209\n",
      "2        2024-11-01           Tosse       348\n",
      "3        2024-11-01          Coriza       365\n",
      "4        2024-11-01   Dor de Cabeça       102\n",
      "..              ...             ...       ...\n",
      "199      2024-12-04   Dor de Cabeça       158\n",
      "200      2024-12-04           Tosse       287\n",
      "201      2024-12-04          Coriza       260\n",
      "202      2024-12-04   Dor de Cabeça        88\n",
      "203      2024-12-04           Tosse       154\n",
      "\n",
      "[204 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertendo 'dataNotificacao' para datetime\n",
    "dataSaude['dataNotificacao'] = pd.to_datetime(dataSaude['dataNotificacao'])\n",
    "\n",
    "# Filtrando pelo município \"São Paulo\" e pela faixa de datas\n",
    "df_filtrado_municipio = dataSaude[\n",
    "    (dataSaude['municipio'] == 'São Paulo') &  # Filtrar pelo município\n",
    "    (dataSaude['dataNotificacao'] >= '2024-11-01') &  # Data inicial\n",
    "    (dataSaude['dataNotificacao'] <= '2024-12-06')  # Data final\n",
    "]\n",
    "\n",
    "# Dividindo sintomas compostos por vírgula e expandindo para várias linhas\n",
    "df_filtrado_municipio['sintomas'] = df_filtrado_municipio['sintomas'].str.split(',')\n",
    "df_filtrado_municipio = df_filtrado_municipio.explode('sintomas')\n",
    "\n",
    "# Filtrando os sintomas desejados\n",
    "sintomas_desejados = ['Tosse', 'Coriza', 'Dor de Cabeça']\n",
    "df_sintomas_filtrados = df_filtrado_municipio[\n",
    "    df_filtrado_municipio['sintomas'].str.strip().isin(sintomas_desejados)\n",
    "]\n",
    "\n",
    "# Agrupando por data e sintomas e contando as ocorrências\n",
    "df_sintomas_agrupados = df_sintomas_filtrados.groupby(\n",
    "    [df_sintomas_filtrados['dataNotificacao'].dt.date, 'sintomas']\n",
    ").size().reset_index(name='contagem')\n",
    "\n",
    "# Ordenando para facilitar a leitura\n",
    "df_sintomas_agrupados = df_sintomas_agrupados.sort_values(by=['dataNotificacao', 'sintomas'])\n",
    "\n",
    "print(df_sintomas_agrupados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas as colunas necessárias\n",
    "df_exportar = df_sintomas_agrupados[['dataNotificacao', 'sintomas']]\n",
    "\n",
    "# Salvando o DataFrame em um arquivo CSV\n",
    "df_exportar.to_csv('sintomas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='525748',\n",
    "    database='bd_medicao'\n",
    ")\n",
    "\n",
    "\n",
    "def process_principais_sintomas(file_path):\n",
    "    with open(file_path, encoding='utf-8') as csv_file:\n",
    "        csv_data = csv.reader(csv_file)\n",
    "        next(csv_data)  # Ignora o cabeçalho\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        for row in csv_data:\n",
    "            try:\n",
    "                # Verificar e ajustar o formato da data\n",
    "                if len(row[0]) == 10:  # Formato YYYY-MM-DD\n",
    "                    data_notificacao = datetime.strptime(row[0], '%Y-%m-%d').strftime('%Y-%m-%d %H:%M:%S')\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato de data inesperado: {row[0]}\")\n",
    "\n",
    "                # Campo de sintomas\n",
    "                sintomas = row[1]\n",
    "\n",
    "                # Inserir no banco de dados\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO principais_sintomas (data_notificacao, sintomas)\n",
    "                    VALUES (%s, %s)\n",
    "                \"\"\", (data_notificacao, sintomas))\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar linha: {row}. Erro: {e}\")\n",
    "\n",
    "        connection.commit()\n",
    "        \n",
    "#process_principais_sintomas('C:/Users/wever/Documents/GitHub/IniciacaoCientifica/Database/principais_sintomas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados poluentes SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataCO = pd.read_csv(r\"C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\ETL\\Arquivos\\dados_CO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCO = dataCO.rename(columns={\"Hora\":\"Data da Coleta\", \"Código Estação\":\"Hora da coleta\", \"Nome Parâmetro\":\"Medida\", \"Unidade de Medida\":\"Média do horário\"})\n",
    "\n",
    "dadosExportar = dataCO[[\"Data da Coleta\",\"Hora da coleta\",\"Medida\",\"Média do horário\"]]\n",
    "\n",
    "#dadosExportar.to_csv('dados_CO.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='525748',\n",
    "    database='bd_medicao'\n",
    ")\n",
    "\n",
    "# Abrindo o arquivo CSV e inserindo dados\n",
    "#with open('C:/Users/wever/Documents/GitHub/IniciacaoCientifica/Database/dados_CO.csv', encoding='utf-8') as csv_file:\n",
    "    csv_data = csv.reader(csv_file)\n",
    "    next(csv_data)  # Ignora o cabeçalho\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    for row in csv_data:\n",
    "        try:\n",
    "            # Ajustar o formato da data\n",
    "            data_da_coleta = datetime.strptime(row[0], '%d/%m/%Y')\n",
    "\n",
    "            # Tratar hora da coleta, incluindo ajuste para 24:00\n",
    "            hora_da_coleta_raw = row[1]\n",
    "            if hora_da_coleta_raw == '24:00':\n",
    "                hora_da_coleta_raw = '00:00'\n",
    "                data_da_coleta += timedelta(days=1)  # Ajusta a data para o próximo dia\n",
    "\n",
    "            # Adicionar segundos, se necessário\n",
    "            if len(hora_da_coleta_raw.split(':')) == 2:  # Formato HH:MM\n",
    "                hora_da_coleta_raw += \":00\"\n",
    "            hora_da_coleta = datetime.strptime(hora_da_coleta_raw, '%H:%M:%S').strftime('%H:%M:%S')\n",
    "\n",
    "            # Combinar data e hora para o formato DATETIME\n",
    "            datetime_hora_da_coleta = f\"{data_da_coleta.strftime('%Y-%m-%d')} {hora_da_coleta}\"\n",
    "\n",
    "            # Outros campos\n",
    "            medida = row[2]\n",
    "\n",
    "            # Substituir vírgulas por pontos no valor float\n",
    "            media_do_horario = float(row[3].replace(',', '.'))\n",
    "\n",
    "            # Inserir no banco de dados\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dados_CO (data_da_coleta, hora_da_coleta, medida, media_do_horario) \n",
    "                VALUES (%s, %s, %s, %s)\n",
    "            \"\"\", (datetime_hora_da_coleta, datetime_hora_da_coleta, medida, media_do_horario))\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar linha: {row}. Erro: {e}\")\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outros poluentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dadosPoluentes = pd.read_csv(r\"C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\ETL\\Arquivos\\dados_poluentes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos no banco!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='525748',\n",
    "    database='bd_medicao'\n",
    ")\n",
    "\n",
    "# Função para converter valores em string para float, tratando espaços em branco ou valores inválidos\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value.strip()) if value.strip() else 0.0  # Substituir por 0.0 em vez de None\n",
    "    except ValueError:\n",
    "        return 0.0  # Substituir por 0.0 se o valor não puder ser convertido\n",
    "\n",
    "# Abrindo o arquivo CSV e inserindo dados\n",
    "with open(r'C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\ETL\\Arquivos\\dados_poluentes.csv', encoding='utf-8') as csv_file:\n",
    "    csv_data = csv.reader(csv_file)\n",
    "    next(csv_data)  # Ignora o cabeçalho\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    for row in csv_data:\n",
    "        try:\n",
    "            # Ajustar o formato da data para 'YYYY/MM/DD'\n",
    "            date = datetime.strptime(row[0].strip(), '%Y/%m/%d')  # Ajuste para o formato correto\n",
    "\n",
    "            # Extrair os valores dos poluentes com a função convert_to_float\n",
    "            pm25 = convert_to_float(row[1])\n",
    "            pm10 = convert_to_float(row[2])\n",
    "            o3 = convert_to_float(row[3])\n",
    "            no2 = convert_to_float(row[4])\n",
    "            so2 = convert_to_float(row[5])  # Agora substitui vazio por 0.0\n",
    "            co = convert_to_float(row[6])\n",
    "\n",
    "            # Inserir no banco de dados\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO dados_poluentes (tempo_registro, pm25, pm10, o3, no2, so2, co) \n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", (date, pm25, pm10, o3, no2, so2, co))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar linha: {row}. Erro: {e}\")\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "print(\"Dados inseridos no banco!\")\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados de temperatura SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataTemp = pd.read_csv(r\"C:\\Users\\wever\\Documents\\GitHub\\IniciacaoCientifica\\ETL\\dados_brasil_Temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosTemperatura = dataTemp[dataTemp[\"City\"] == \"São Paulo\"]\n",
    "\n",
    "#dadosTemperatura = dadosTemperatura.to_csv('dados_temperatura_SP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='525748',\n",
    "    database='bd_medicao'\n",
    ")\n",
    "\n",
    "def process_dados_temperatura_SP(file_path):\n",
    "    with open(file_path, encoding='utf-8') as csv_file:\n",
    "        csv_data = csv.reader(csv_file)\n",
    "        next(csv_data)  # Ignora o cabeçalho\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        for row in csv_data:\n",
    "            try:\n",
    "                # Verificar e ajustar o formato da data\n",
    "                if len(row[0]) == 10:  # Formato YYYY-MM-DD\n",
    "                    date = datetime.strptime(row[0], '%Y-%m-%d').strftime('%Y-%m-%d %H:%M:%S')\n",
    "                else:\n",
    "                    raise ValueError(f\"Formato de data inesperado: {row[0]}\")\n",
    "\n",
    "                # Outros campos\n",
    "                country = row[1]\n",
    "                city = row[2]\n",
    "                count = int(row[4])\n",
    "                min_temp = float(row[5].replace(',', '.'))\n",
    "                max_temp = float(row[6].replace(',', '.'))\n",
    "                median = float(row[7].replace(',', '.'))\n",
    "                variance = float(row[8].replace(',', '.'))\n",
    "\n",
    "                # Inserir no banco de dados\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO dados_temperatura_SP (date, country, city, count, min, max, median, variance)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", (date, country, city, count, min_temp, max_temp, median, variance))\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar linha: {row}. Erro: {e}\")\n",
    "\n",
    "        connection.commit()\n",
    "\n",
    "#process_dados_temperatura_SP('C:/Users/wever/Documents/GitHub/IniciacaoCientifica/Database/dados_temperatura_SP.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados Sensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importação concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='senai@134',\n",
    "    database='bd_medicao'\n",
    ")\n",
    "\n",
    "def insert_batch(file_path):\n",
    "    with open(file_path, encoding='utf-8') as csv_file:\n",
    "        csv_data = csv.reader(csv_file, delimiter=';')\n",
    "        next(csv_data)  # Ignorar o cabeçalho\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        batch_size = 1000  # Define o tamanho do lote\n",
    "        batch = []\n",
    "\n",
    "        for row in csv_data:\n",
    "            try:\n",
    "                # Substituir vírgulas por pontos para valores decimais\n",
    "                temperatura = float(row[0].replace(',', '.'))\n",
    "                pressao = float(row[1].replace(',', '.'))\n",
    "                altitude = float(row[2].replace(',', '.'))\n",
    "\n",
    "                # Tratar \"NULL\" e converter para None\n",
    "                umidade = None if row[3].strip().upper() == \"NULL\" else int(row[3])\n",
    "                co2 = None if row[4].strip().upper() == \"NULL\" else float(row[4].replace(',', '.'))\n",
    "                tempo_registro = datetime.strptime(row[5], '%d/%m/%Y %H:%M').strftime('%Y-%m-%d %H:%M:%S')\n",
    "                regiao = row[6]\n",
    "\n",
    "                # Adicionar os valores ao lote\n",
    "                batch.append((temperatura, pressao, altitude, umidade, co2, tempo_registro, regiao))\n",
    "\n",
    "                # Insere o lote quando atinge o tamanho definido\n",
    "                if len(batch) >= batch_size:\n",
    "                    cursor.executemany(\"\"\"\n",
    "                        INSERT INTO tb_registro (temperatura, pressao, altitude, umidade, co2, tempo_registro, regiao)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", batch)\n",
    "                    connection.commit()\n",
    "                    batch = []  # Limpa o lote\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar linha: {row}. Erro: {e}\")\n",
    "\n",
    "        # Insere o restante dos dados\n",
    "        if batch:\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO tb_registro (temperatura, pressao, altitude, umidade, co2, tempo_registro, regiao)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", batch)\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Importação concluída com sucesso!\")\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "file_path = r'C:\\Users\\50749314877\\Desktop\\Git\\IniciacaoCientifica\\ETL\\Arquivos\\dadosSensores.csv'\n",
    "\n",
    "# Executar a função\n",
    "insert_batch(file_path)\n",
    "\n",
    "# Fechar a conexão com o banco de dados\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
